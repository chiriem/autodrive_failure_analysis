import streamlit as st
import altair as alt
from altair.datasets import data
import polars as pl
import numpy as np
import statsmodels.api as sm
import openai


st.set_page_config(
    page_title="ì‹¤íŒ¨ë¶„ì„", page_icon=":clapper:", layout="wide"
)

# --- Mock Data Generation for Autonomous Driving ---
def generate_autonomous_data(n=1000):
    np.random.seed(42)
    weather_opts = ["Sunny", "Cloudy", "Rainy", "Snowy", "Foggy"]
    
    # Generate base data
    weather = np.random.choice(weather_opts, n)
    time_of_day = np.random.choice(["Day", "Night"], n, p=[0.7, 0.3])
    white_line_present = np.random.choice([True, False], n, p=[0.9, 0.1]) # 90% frames have lines
    
    # Simulate Confidence and IoU (correlated but with noise)
    confidence = np.random.beta(5, 2, n) * 10  # Scale 0-10
    iou = (confidence * 10) + np.random.normal(0, 10, n) # Scale 0-100
    iou = np.clip(iou, 0, 100)
    
    # Inject Failures: White line exists, but low confidence/IoU (e.g., in Snowy/Rainy)
    mask_failure = (weather == "Snowy") | (weather == "Rainy")
    mask_night = (time_of_day == "Night")

    confidence[mask_failure] = confidence[mask_failure] * 0.6
    iou[mask_failure] = iou[mask_failure] * 0.5
    
    # Additional penalty for Night
    confidence[mask_night] = confidence[mask_night] * 0.9
    iou[mask_night] = iou[mask_night] * 0.85

    df = pl.DataFrame({
        "Frame ID": [f"frame_{i:05d}" for i in range(n)],
        "Weather": weather,
        "Time of Day": time_of_day,
        "White Line Present": white_line_present,
        "Model Confidence": confidence,
        "IoU Score": iou,
        "Processing Time (ms)": np.random.normal(30, 5, n),
    })
    return df

df = generate_autonomous_data()
TITLE_COL = "Frame ID"
IMDB_COL = "Model Confidence"  # 0-10 scale
RT_COL = "IoU Score"           # 0-100 scale
DIRECTOR_COL = "Weather"
HAS_RATINGS = pl.col("White Line Present") == True # Only analyze frames where line exists
TEXT_WIDTH = 700
SMALLPLOT_WIDTH = 500
SMALLPLOT_HEIGHT = 500
MARK_SIZE = 70
DIRECTOR_MARK_SIZE = 150

COLUMN_CONFIG = {
    TITLE_COL: st.column_config.TextColumn(pinned=True),
    IMDB_COL: st.column_config.ProgressColumn(
        min_value=0,
        max_value=10,
        color="#f28e2b",
        format="compact",
        width=100,
    ),
    RT_COL: st.column_config.ProgressColumn(
        min_value=0,
        max_value=100,
        color="#4e79a7",
        format="compact",
        width=100,
    ),
    "Processing Time (ms)": st.column_config.NumberColumn(format="%.1f ms"),
    "Weather": st.column_config.TextColumn(),
    "Time of Day": st.column_config.TextColumn(),
    "White Line Present": st.column_config.CheckboxColumn(),
    "Status": st.column_config.TextColumn(
        width="medium",
    ),
}

# -----------------------------------------------------------------------------
# Helpful functions


def draw_histogram(df, metric_name):
    # Ensure we don't have nulls for the main metric
    clean_df = df.drop_nulls(subset=[metric_name])

    st.altair_chart(
        alt.Chart(clean_df, height=200, width=200)
        .mark_bar(binSpacing=0)
        .encode(
            alt.X(
                metric_name,
                type="quantitative",
            ).bin(maxbins=20),
            alt.Y("count()").axis(None),
        )
    )


def draw_director_median_chart(title, data, x_col, y_col, x_domain, color_domain):
    data = data.drop_nulls(subset=[y_col])

    medians = (
        data.group_by(y_col)
        .agg(pl.col(x_col).median().alias("median_val"))
        .sort("median_val", descending=True)
    )

    sort_order = medians.get_column(y_col).to_list()

    base = alt.Chart(data).encode(
        alt.Y(f"{y_col}:N", sort=sort_order, title=None),
    )

    points = base.mark_point(filled=True, size=DIRECTOR_MARK_SIZE).encode(
        alt.X(f"{x_col}:Q", title=f"{x_col}").scale(zero=True, domain=x_domain),
        alt.Color(DIRECTOR_COL, type="nominal").scale(domain=color_domain).legend(None),
        alt.Shape(DIRECTOR_COL, type="nominal").scale(domain=color_domain).legend(None),
        tooltip=[y_col, x_col, TITLE_COL],
    )

    ticks = (
        alt.Chart(medians.to_pandas())
        .mark_tick(
            color="red",
            thickness=2,
        )
        .encode(
            alt.Y(f"{y_col}:N", sort=sort_order),
            alt.X("median_val:Q"),
            tooltip=[alt.Tooltip("median_val:Q", title="Median Rating")],
        )
    )

    st.subheader(title)
    st.altair_chart(points + ticks, width="stretch")


def perform_linear_regression(df, x_col, y_col, sigma_threshold):
    clean_df = df.drop_nulls([x_col, y_col])

    x = clean_df[x_col].to_numpy()
    y = clean_df[y_col].to_numpy()

    # Degree 1 = Linear
    slope, intercept = np.polyfit(x, y, 1)

    predictions = (slope * x) + intercept
    residuals = y - predictions
    std_dev = np.std(residuals)

    upper_bound = predictions + (sigma_threshold * std_dev)
    lower_bound = predictions - (sigma_threshold * std_dev)

    result_df = clean_df.with_columns(
        [
            pl.Series("Predicted", predictions),
            pl.Series("Upper Bound", upper_bound),
            pl.Series("Lower Bound", lower_bound),
            # Determine Status: Outlier if outside the bounds
            pl.when(
                (pl.col(y_col) > pl.Series(upper_bound))
                | (pl.col(y_col) < pl.Series(lower_bound))
            )
            .then(pl.lit("Outlier"))
            .otherwise(pl.lit("In Range"))
            .alias("Status"),
        ]
    )

    return result_df


def perform_loess_regression(df, x_col, y_col, sigma_threshold, frac=0.66):
    """
    Calculates LOESS regression, residuals, and outlier status using Polars and Statsmodels.

    Args:
        frac (float): The fraction of the data used when estimating each y-value.
                      Between 0 and 1. Defaults to 0.66 (standard).
    """
    # Sorting by x_col is mandatory for LOESS to align predictions correctly for plotting
    clean_df = df.drop_nulls([x_col, y_col]).sort(x_col)

    x = clean_df[x_col].to_numpy()
    y = clean_df[y_col].to_numpy()

    # Returns an (n, 2) array: [sorted_x, fitted_y]
    lowess_result = sm.nonparametric.lowess(y, x, frac=frac)

    predictions = lowess_result[:, 1]

    residuals = y - predictions
    std_dev = np.std(residuals)

    upper_bound = predictions + (sigma_threshold * std_dev)
    lower_bound = predictions - (sigma_threshold * std_dev)

    result_df = clean_df.with_columns(
        [
            pl.Series("Predicted", predictions),
            pl.Series("Upper Bound", upper_bound),
            pl.Series("Lower Bound", lower_bound),
            pl.when(
                (pl.col(y_col) > pl.Series(upper_bound))
                | (pl.col(y_col) < pl.Series(lower_bound))
            )
            .then(pl.lit("Outlier"))
            .otherwise(pl.lit("In Range"))
            .alias("Status"),
        ]
    )

    return result_df


def wide_centered_layout():
    with st.container(horizontal_alignment="center"):
        return st.container(
            width=2 * SMALLPLOT_WIDTH + 16, horizontal_alignment="center"
        )


# -----------------------------------------------------------------------------
# Draw app


with wide_centered_layout():
    with st.container(width=TEXT_WIDTH):
        st.title("ììœ¨ì£¼í–‰ ì°¨ì„  ì¸ì‹ ì‹¤íŒ¨ ë¶„ì„")

        st.space()

        """
        ## Part I: Detection Performance

        **ëª¨ë¸ì˜ í™•ì‹ (Confidence)ê³¼ ì‹¤ì œ ì •í™•ë„(IoU)ì˜ ê´€ê³„ëŠ”?**
        ì•„ë˜ ë¶„ì„ì—ì„œ **Model Confidence**ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì°¨ì„ ì„ ì¸ì‹í–ˆë‹¤ê³  ë¯¿ëŠ” ì •ë„ì´ë©°,
        **IoU Score**ëŠ” ì‹¤ì œ ì •ë‹µ(Ground Truth)ê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

        ì¼ë°˜ì ìœ¼ë¡œ ë‘ ì§€í‘œëŠ” ì–‘ì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
        :green[**ì´ˆë¡ìƒ‰ ì‹­ìê°€(Outlier)**]ëŠ” ëª¨ë¸ì´ ê³¼ì‹ í–ˆê±°ë‚˜(Confidence ë†’ìŒ, IoU ë‚®ìŒ),
        ì˜ˆìƒë³´ë‹¤ ì˜ ë§ì¶˜ ì¼€ì´ìŠ¤ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
        """

    rating_df = (
        df.filter(HAS_RATINGS)
        .select(TITLE_COL, DIRECTOR_COL, IMDB_COL, RT_COL)
        .with_columns(
            delta=pl.col(IMDB_COL) / 10 - pl.col(RT_COL) / 100,
        )
    )

    rating_model_df = perform_linear_regression(
        rating_df, IMDB_COL, RT_COL, sigma_threshold=2
    )

    st.space()

    with st.container(width=TEXT_WIDTH):
        cols = st.columns([0.7, 0.3])

        with cols[0]:
            st.subheader("Confidence vs IoU Correlation")
            st.altair_chart(
                alt.Chart(rating_model_df)
                .mark_point(filled=True, size=MARK_SIZE, opacity=0.5)
                .encode(
                    alt.X(IMDB_COL, type="quantitative"),
                    alt.Y(RT_COL, type="quantitative"),
                    alt.Color("Status:N").legend(None),
                    alt.Shape("Status:N").scale(range=["circle", "cross"]).legend(None),
                    tooltip=[TITLE_COL, DIRECTOR_COL, IMDB_COL, RT_COL, "Status"],
                ),
                height="stretch",
            )

        with cols[1]:
            st.space("medium")
            draw_histogram(rating_df, IMDB_COL)
            draw_histogram(rating_df, RT_COL)

    diff_df = rating_df.filter(
        pl.col(IMDB_COL).is_not_null() & pl.col(RT_COL).is_not_null()
    ).sort(by="delta", descending=True)

    help_text = (
        "Confidenceì™€ IoUì˜ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤."
    )

    st.space()

    cols = st.columns(2, border=True)
    with cols[0]:
        st.subheader(
            "Over-confident Failures (False Positives)",
            help=help_text,
        )

        st.dataframe(
            diff_df.select(pl.exclude("delta"))
            .head(20)
            .sort(by=IMDB_COL, descending=True),
            column_config=COLUMN_CONFIG,
            height="stretch",
        )

    with cols[1]:
        st.subheader(
            "Under-confident Successes",
            help=help_text,
        )

        st.dataframe(
            diff_df.select(pl.exclude("delta"))
            .tail(20)
            .sort(by=RT_COL, descending=True),
            column_config=COLUMN_CONFIG,
            height="stretch",
        )

    # -----------------------------------------------------------------------------
    # Part 2

    st.space("large")

    with st.container(width=TEXT_WIDTH):
        """
        ## Part II: Environmental Analysis (Weather)

        **ì–´ë–¤ ë‚ ì”¨ í™˜ê²½ì—ì„œ ì¸ì‹ì´ ê°€ì¥ ì‹¤íŒ¨í• ê¹Œìš”?**

        ì•„ë˜ ì°¨íŠ¸ëŠ” ë‚ ì”¨(Weather)ë³„ë¡œ Confidenceì™€ IoUì˜ ì¤‘ì•™ê°’(Median) ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        íŠ¹ì • ë‚ ì”¨(ì˜ˆ: Snowy, Rainy)ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """

        min_movies = st.slider(
            "Minimum frames per weather condition",
            min_value=1,
            max_value=50,
            value=10,
        )

        director_df = rating_df.filter(pl.col(DIRECTOR_COL).is_not_null()).with_columns(
            first_letter=pl.col(DIRECTOR_COL).str.head(1)
        )

        director_medians_df = (
            director_df.group_by(DIRECTOR_COL)
            .agg(
                **{
                    "num_movies": pl.len(),
                    "first_letter": pl.col("first_letter").first(),
                    IMDB_COL: pl.col(IMDB_COL).median(),
                    RT_COL: pl.col(RT_COL).median(),
                }
            )
            .filter(pl.col("num_movies") >= min_movies)
        )

        all_directors_list = director_medians_df.get_column(DIRECTOR_COL).to_list()

        st.space()

        st.subheader("Performance by Weather Condition")
        st.altair_chart(
            alt.Chart(director_medians_df, height=SMALLPLOT_HEIGHT)
            .mark_point(filled=True, size=DIRECTOR_MARK_SIZE)
            .encode(
                alt.X(IMDB_COL, type="quantitative"),
                alt.Y(RT_COL, type="quantitative"),
                alt.Color(DIRECTOR_COL, type="nominal")
                .scale(domain=all_directors_list)
                .legend(None),
                alt.Shape(DIRECTOR_COL, type="nominal")
                .scale(domain=all_directors_list)
                .legend(None),
                tooltip=[DIRECTOR_COL, IMDB_COL, RT_COL, "num_movies"],
            )
        )

    st.space()

    for i in range(2):
        if i == 0:
            metric_name = IMDB_COL
            director_medians_df = director_medians_df.filter(
                pl.col(IMDB_COL).is_not_null()
            )
            x_domain = [0, 10]
        else:
            metric_name = RT_COL
            director_medians_df = director_medians_df.filter(
                pl.col(RT_COL).is_not_null()
            )
            x_domain = [0, 100]

        cols = st.columns(2, border=True)

        with cols[0]:
            top_directors_df = director_medians_df.sort(
                metric_name, descending=True
            ).head(10)

            top_directors_set = set(top_directors_df.get_column(DIRECTOR_COL).to_list())

            top_dir_df = director_df.filter(
                pl.col(DIRECTOR_COL).is_in(top_directors_set)
            )

            draw_director_median_chart(
                f"Best Conditions by {metric_name}",
                data=top_dir_df,
                x_col=metric_name,
                y_col=DIRECTOR_COL,
                x_domain=x_domain,
                color_domain=all_directors_list,
            )

        with cols[1]:
            bottom_directors_df = director_medians_df.sort(metric_name).head(10)

            bottom_directors_set = set(
                bottom_directors_df.get_column(DIRECTOR_COL).to_list()
            )

            bottom_dir_df = director_df.filter(
                pl.col(DIRECTOR_COL).is_in(bottom_directors_set)
            )

            draw_director_median_chart(
                f"Worst Conditions by {metric_name}",
                data=bottom_dir_df,
                x_col=metric_name,
                y_col=DIRECTOR_COL,
                x_domain=x_domain,
                color_domain=all_directors_list,
            )

    # -----------------------------------------------------------------------------
    # Part 3

    st.space("large")

    with st.container(width=TEXT_WIDTH):
        """
        ## Part III: Failure Prediction & Outliers

        **í°ìƒ‰ ì„ ì„ ì¸ì§€í•˜ì§€ ëª»í•˜ëŠ” ì‹¤íŒ¨ ì¼€ì´ìŠ¤(Outlier) íƒì§€**
        íšŒê·€ ë¶„ì„ì„ í†µí•´ ì˜ˆìƒë˜ëŠ” ì„±ëŠ¥ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” í”„ë ˆì„ì„ ì°¾ìŠµë‹ˆë‹¤.
        íŠ¹íˆ **í°ìƒ‰ ì„ ì´ ì¡´ì¬í•¨ì—ë„ ë¶ˆêµ¬í•˜ê³ (Ground Truth)** ëª¨ë¸ ìˆ˜ì¹˜ê°€ ë‚®ì€ ê²½ìš°ë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.
        """

    numeric_cols = [
        "Model Confidence",
        "IoU Score",
        "Processing Time (ms)",
    ]

    with st.container(width=TEXT_WIDTH):
        st.space()

        cols = st.columns(2)

        with cols[0]:
            x_col = st.selectbox(
                "X Axis (predictor)", options=numeric_cols, index=0
            )  # Default Confidence

        with cols[1]:
            y_col = st.selectbox(
                "Y Axis (target)", options=numeric_cols, index=1
            )  # Default IoU

        sigma_val = st.slider(
            "Confidence interval (sigma)",
            min_value=0.5,
            max_value=4.0,
            value=2.0,
            step=0.1,
            help="Determines the width of the confidence band. Points outside this band are outliers.",
        )

        regression_type = st.segmented_control(
            "Regression type",
            ["Linear regression", "LOESS regression"],
            default="Linear regression",
        )

        if not x_col or not y_col:
            st.info("Please select columns to visualize.")
            st.stop()

        if regression_type == "Linear regression":
            model_df = perform_linear_regression(df, x_col, y_col, sigma_val)
        else:
            model_df = perform_loess_regression(df, x_col, y_col, sigma_val)

        outliers = model_df.filter(pl.col("Status") == "Outlier").select(
            TITLE_COL, DIRECTOR_COL, IMDB_COL, RT_COL
        )
        num_outliers = len(model_df.filter(pl.col("Status") == "Outlier"))

        st.space()

        with st.container(height=SMALLPLOT_HEIGHT, border=False):
            base = alt.Chart(model_df).encode(
                alt.X(x_col, title=x_col, scale=alt.Scale(zero=False))
            )

            band = base.mark_area(opacity=0.1).encode(
                alt.Y("Lower Bound"),
                alt.Y2("Upper Bound"),
                tooltip=[
                    alt.Tooltip("Lower Bound", format=",.0f"),
                    alt.Tooltip("Upper Bound", format=",.0f"),
                ],
            )

            line = base.mark_line(size=3).encode(y="Predicted")

            points = base.mark_point(filled=True, size=MARK_SIZE, opacity=0.5).encode(
                alt.Y(y_col, title=y_col),
                alt.Color(
                    "Status:N",
                ).legend(None),
                alt.Shape("Status:N").scale(range=["circle", "cross"]).legend(None),
                tooltip=[TITLE_COL, x_col, y_col],
            )

            final_chart = (band + points + line).configure_legend(orient="bottom")

            st.subheader(f"{y_col} by {x_col}")
            st.altair_chart(final_chart, width="stretch", height="stretch")

    st.subheader("Detected Failures (Outliers)")

    """
    ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²½í–¥ì„±ì—ì„œ ë²—ì–´ë‚œ í”„ë ˆì„ë“¤ì…ë‹ˆë‹¤. (í°ìƒ‰ ì„  ë¯¸ì¸ì‹ ë“±)
    """

    with st.container(horizontal=True):
        with st.container(width="content"):
            with st.container(border=True, width="content"):
                st.metric(
                    "Number of outliers",
                    num_outliers,
                    help="ì¼ë°˜ì ì¸ ì„±ëŠ¥ ë¶„í¬ì—ì„œ ë²—ì–´ë‚œ í”„ë ˆì„ ìˆ˜",
                )

        with st.container(width="stretch"):
            st.dataframe(outliers, column_config=COLUMN_CONFIG, height=SMALLPLOT_HEIGHT)

    # -----------------------------------------------------------------------------
    # Part 4

    st.space("large")

    """
    ## Part IV: Day vs Night Failure Analysis

    **ì£¼ê°„(Day)ê³¼ ì•¼ê°„(Night)ì˜ ììœ¨ì£¼í–‰ ì‹¤íŒ¨ìœ¨ ë¹„êµ**
    
    IoU Scoreê°€ 50ì  ë¯¸ë§Œì¸ ê²½ìš°ë¥¼ 'ì‹¤íŒ¨'ë¡œ ê°„ì£¼í•˜ì—¬ ì‹œê°„ëŒ€ë³„ ì‹¤íŒ¨ìœ¨ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """

    with st.container(width=TEXT_WIDTH):
        failure_threshold = 50
        
        day_night_stats = (
            df.filter(pl.col("White Line Present") == True)
            .with_columns(
                (pl.col("IoU Score") < failure_threshold).alias("is_failure")
            )
            .group_by("Time of Day")
            .agg(
                [
                    pl.len().alias("total"),
                    pl.col("is_failure").sum().alias("failures")
                ]
            )
            .with_columns(
                (pl.col("failures") / pl.col("total") * 100).alias("failure_rate")
            )
        )

        # Calculate difference for explanation
        day_data = day_night_stats.filter(pl.col("Time of Day") == "Day")
        night_data = day_night_stats.filter(pl.col("Time of Day") == "Night")
        
        day_rate = day_data["failure_rate"][0] if not day_data.is_empty() else 0.0
        night_rate = night_data["failure_rate"][0] if not night_data.is_empty() else 0.0
        diff = night_rate - day_rate

        st.metric(
            label="ì•¼ê°„ vs ì£¼ê°„ ì‹¤íŒ¨ìœ¨ ì°¨ì´",
            value=f"{diff:+.1f}%p",
            delta=f"ì•¼ê°„ ì‹¤íŒ¨ìœ¨ {night_rate:.1f}% (ì£¼ê°„ {day_rate:.1f}%)",
            delta_color="inverse"
        )

        if diff > 0:
            st.info(f"ğŸ’¡ **ë¶„ì„ ê²°ê³¼**: ì•¼ê°„ ì£¼í–‰ ì‹œ ì°¨ì„  ì¸ì‹ ì‹¤íŒ¨ í™•ë¥ ì´ ì£¼ê°„ë³´ë‹¤ **{diff:.1f}%** ë” ë†’ìŠµë‹ˆë‹¤. ì´ìœ ëŠ” ë‚®ì€ ë°ê¸°ë¡œ ì¸í•´ ì¹´ë©”ë¼ê°€ ì„ ì„ ì¸ì‹í•˜ê¸° ì–´ë ¤ì›Œì¡Œê¸° ë•Œë¬¸ìœ¼ë¡œ ì¶”ì¸¡ë©ë‹ˆë‹¤.")
        else:
            st.success(f"ğŸ’¡ **ë¶„ì„ ê²°ê³¼**: ì•¼ê°„ ì£¼í–‰ ì„±ëŠ¥ì´ ì£¼ê°„ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ë” ìš°ìˆ˜í•©ë‹ˆë‹¤.")

        dn_chart = (
            alt.Chart(day_night_stats)
            .mark_bar()
            .encode(
                x=alt.X("Time of Day", axis=alt.Axis(title="Time of Day")),
                y=alt.Y("failure_rate", axis=alt.Axis(title="Failure Rate (%)")),
                color="Time of Day",
                tooltip=["Time of Day", alt.Tooltip("failure_rate", format=".1f"), "failures", "total"]
            )
        )
        st.altair_chart(dn_chart, use_container_width=True)

    st.space("large")

    """
    ## Part V: Browse Full Log Data
    """

    st.space()

    st.dataframe(
        df,
        height=SMALLPLOT_HEIGHT,
        column_config=COLUMN_CONFIG,
    )

    # -----------------------------------------------------------------------------
    # Part 6: AI Assistant

    st.space("large")
    st.divider()

    with st.container(width=TEXT_WIDTH):
        st.header("Part VI: AI Analysis Assistant")
        
        """
        **ë°ì´í„° ë¶„ì„ ìš”ì•½ ë° ì§ˆì˜ì‘ë‹µ**
        
        OpenAIì˜ LLMì„ í™œìš©í•˜ì—¬ í˜„ì¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì§ˆë¬¸ì„ í•˜ê±°ë‚˜ ìš”ì•½ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. AI ë‹µë³€ì€ ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """

        use_ai = st.checkbox("ëŒ€í™”í˜• AIë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")

        if use_ai:
            openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
            
            if not openai_api_key:
                st.info("AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                if "messages" not in st.session_state:
                    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í˜„ì¬ ë¡œë“œëœ ììœ¨ì£¼í–‰ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"}]

                for msg in st.session_state.messages:
                    st.chat_message(msg["role"]).write(msg["content"])

                if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì•¼ê°„ ì£¼í–‰ ì‹œ ì‹¤íŒ¨ìœ¨ì´ ë†’ì€ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?)"):
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    st.chat_message("user").write(prompt)
                    
                    # Convert Polars describe to string for the LLM context
                    data_summary = df.describe().to_pandas().to_string()
                    
                    system_instruction = f"""ë‹¹ì‹ ì€ ììœ¨ì£¼í–‰ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                    ë‹¤ìŒì€ í˜„ì¬ ë°ì´í„°ì…‹ì˜ í†µê³„ ìš”ì•½ ì •ë³´ì…ë‹ˆë‹¤:
                    {data_summary}

                    ì•¼ê°„ì˜ ì„±ëŠ¥ì— ê´€ë ¨ëœ ì§ˆë¬¸ì´ ìˆì„ ê²½ìš°, ë‚®ì€ ë°ê¸°ë¡œ ì¸í•´ ì¹´ë©”ë¼ì˜ ì°¨ì„  ì¸ì‹ë¥ ì´ ë‚®ì•„ì§€ê¸° ë•Œë¬¸ì´ë¼ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
                    
                    ì‚¬ìš©ìê°€ ì´ ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ìœ„ í†µê³„ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
                    ë§Œì•½ ì‚¬ìš©ìê°€ ë°ì´í„°ì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì„ í•œë‹¤ë©´ ëŒ€ë‹µì„ ê±°ì ˆí•˜ê³  ë‹¤ì‹œ ì§ˆë¬¸ì„ ìš”ì²­í•˜ì„¸ìš”
                    ë‹µë³€ì´ ì–´ë ¤ìš°ë©´ ì¼ë°˜ì ì¸ ë‹µë³€ë„ ì¢‹ìŠµë‹ˆë‹¤.
                    ë‹µë³€ì€ ê°„ê²°í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
                    ì‚¬ìš©ìì—ê²Œ ê¶Œì¥ì„ í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.
                    """

                    client = openai.OpenAI(api_key=openai_api_key)
                    response = client.chat.completions.create(
                        model="gpt-5-mini", 
                        messages=[{"role": "system", "content": system_instruction}] + st.session_state.messages
                    )
                    msg = response.choices[0].message.content
                    st.session_state.messages.append({"role": "assistant", "content": msg})
                    st.chat_message("assistant").write(msg)
